# English
This project aims to model annotated texts with spatio-temporal information (tweets or geotagged stories), usually tuples in the form <text, place, time>. He is usually a pair <latitude, longitude> and the one timestamp. The objective of the models is to be able to answer questions about one of the three elements with the others. For example: given a place and time which is the text that characterizes that place and time. Given a word which is time or the place or time that is best associated with that word. The processing of tuples is through a file that represents a dataframe from the python pandas library. The file must be in .pickle or .csv format. This code is not responsible for downloading tweets or some other type of geo-tagged data, the code assumes that data is already owned. The file must have four columns named 'created_at', 'latitude', 'longitude' and 'texts'. The utils.py file is the code corresponding to the loading and preprocessing of the data. In preprocessing all words are converted to lowercase, stop-words are eliminated and non-alphanumeric words are eliminated. The coordinates and timestamp are also discretized according to the desired granularity. The jupyter notebook Represent_As_Doc.ipynb has representation models as texts. These models consist of: representing each time window as the aggregation of the texts that appear in the window, representing each space cell as the aggregation of the texts that appear in the window and representing each word as the aggregation of the texts in which that text appears word. Then text representation models such as TF, TF-IDF, LDA are used. In the experiments performed the best results were obtained with TF. The code presented in Represent_As_Doc.ipynb is designed to work in google-collaborative but is easily adaptable to local environments. The construction of the models takes time in the range of 5 minutes.


# Español
Este proyecto tiene como objetivo modelar textos anotados con informacion espacio-temporal (tweets o los relatos geoetiquetados), usualmente tuplas en la forma <texto, lugar, tiempo>. El <lugar> es usualmente un par <latitud,longitud> y el <tiempo> un timestamp. El objetivo de los modelos es ser capaces de responder consultas de alguno de los tres elementos con los otros. Por ejemplo: dado un lugar y horario cual es el texto que caracteriza ese lugar y horario. Dada una palabra cual es horario o el lugar o horario que mejor se asocia a esa palabra.
El procesamiento de las tuplas es a traves de un fichero que representa un dataframe de la biblioteca pandas de python.
El fichero debe estar en formato .pickle o .csv. Este codigo no se encarga de descargar tweets o algun otro tipo de datos geoetiquetados, el codigo asume que ya se poseen esos datos. El fichero debe tener cuatro columnas nombradas 'created_at', 'latitude', 'longitude' y 'texts'.
El fichero utils.py esta el codigo correspondiente a la carga y preprocesamiento de los datos. En el preprocesamiento se convierten todas las palabras a minusculas, se eliminan stop-words y se eliminan palabras no alfanumericas.Tambien se discretizan las coordenadas y el timestamp de acuerdo a la granularidad deseada.
El jupyter notebook Represent_As_Doc.ipynb tiene los modelos de representacion como textos. Estos modelos consisten en: representar cada ventana temporal como la agregacion de los textos que aparecen en la ventana, representar cada celda  espacial como la agregacion de los textos que aparecen en la ventana y representar cada palabra como la agregacion de los textos en que aparece esa palabra. Luego se utilizan modelos de representacion de textos como TF, TF-IDF, LDA. En los experimentos realizados los mejores resultados se obtuvieron con TF. El codigo presentado en Represent_As_Doc.ipynb esta diseñado para trabajar en google-colaboratory aunque es facilmente adaptable a ambientes locales.
La construccion de los modelos toma un tiempo en el rango de los 5 minutos.
 

